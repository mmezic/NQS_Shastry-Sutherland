{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Shastry-Sutterland model with RBM variational wave function and other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetKet version: 3.3.2.post1\n",
      "NumPy version: 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import netket as nk\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import flax\n",
    "import optax\n",
    "print(\"NetKet version: {}\".format(nk.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup relevant parameters and settings of the simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lattice\"\"\"\n",
    "SITES    = 16             # 4, 8, 16, 20 ... number of vertices in a tile determines the tile shape \n",
    "JEXCH1   = .9            # nn interaction\n",
    "JEXCH2   = 1             # nnn interaction\n",
    "TOTAL_SZ = None          # 0, None ... restriction of Hilbert space\n",
    "#USE_MSR = True          # Should we use a Marshall sign rule? In this notebook, we use both.\n",
    "\n",
    "\"\"\"machine learning\"\"\"\n",
    "MACHINE  = \"RBM\"         # RBM, RBMSymm, RBMSymm_transl, RBMModPhase, GCNN, Jastrow\n",
    "DTYPE    = np.complex128 # data-type of weights in neural network\n",
    "ALPHA    = 8            # N_hidden / N_visible\n",
    "ETA      = .01          # learning rate (0.01 usually works)\n",
    "SAMPLER  = 'exact'       # 'local' = MetropolisLocal, 'exchange' = MetropolisExchange\n",
    "SAMPLES  = 1000          # number of Monte Carlo samples\n",
    "NUM_ITER = 400           # number of convergence iterations\n",
    "N_LAYERS = 1 #2             # number of layers (in case of G-CNN)\n",
    "FEATURES = 16 #(8,4)         # dimensions of layers (in case of G-CNN)\n",
    "\n",
    "OUT_NAME = \"SS_\"+str(SITES)+\"j1=\"+str(JEXCH1) # output file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lattice definition\n",
    "Basic structure of tiled lattices is implemented in `lattice_and_ops.py` file. Class `Lattice` implements relative positional functions, \n",
    "- e.g. *`rt(node)` returns the index of the right neighbour of a site with index `node`*\n",
    "\n",
    "The `for` loop constructs full Shastry-Sutherland lattice with PBC using these auxiliary positional functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice_and_ops import Lattice\n",
    "lattice = Lattice(SITES)\n",
    "\n",
    "# Construction of custom graph according to tiled lattice structure defined in the Lattice class.\n",
    "edge_colors = []\n",
    "for node in range(SITES):\n",
    "    edge_colors.append([node,lattice.rt(node), 1])  # horizontal connections\n",
    "    edge_colors.append([node,lattice.bot(node), 1]) # vertical connections\n",
    "    row, column = lattice.position(node)\n",
    "    if column%2 == 0:\n",
    "        if row%2 == 0:\n",
    "            edge_colors.append([node,lattice.lrt(node),2]) # diagonal bond\n",
    "        else:\n",
    "            edge_colors.append([node,lattice.llft(node),2]) # diagonal bond\n",
    "\n",
    "g = nk.graph.Graph(edges=edge_colors) #,n_nodes=3)\n",
    "N = g.n_nodes\n",
    "\n",
    "hilbert = nk.hilbert.Spin(s=.5, N=g.n_nodes, total_sz=TOTAL_SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alternative (simple) toy lattices'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"alternative (simple) toy lattices\"\"\"\n",
    "\n",
    "# # two dimers\n",
    "# edge_colors.append([0,1,1])\n",
    "# edge_colors.append([2,3,1])\n",
    "\n",
    "# # SS 2x2 lattice:\n",
    "# edge_colors.append([0,1,1])\n",
    "# edge_colors.append([2,3,1])\n",
    "# edge_colors.append([1,2,1])\n",
    "# edge_colors.append([0,3,1])\n",
    "# edge_colors.append([0,2,2])\n",
    "# edge_colors.append([1,3,2])\n",
    "\n",
    "# # 3-chain:\n",
    "# edge_colors.append([0,1,1])\n",
    "# edge_colors.append([1,2,1])\n",
    "# edge_colors.append([2,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters of the symmetries\n",
    "In case of G-CNN, we need to specify the characters of the symmetry transformations.\n",
    "- DS phase anti-symmetric wrt permutations with negative sign and symmetric wer permutaions with postive sign\n",
    "- AF phase is always symmetric for all permutations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64 full symmetries.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"There are\", len(g.automorphisms()), \"full symmetries.\")\n",
    "# deciding point between DS and AF phase is set to 0.5\n",
    "if JEXCH1 < 0.5:\n",
    "    # DS phase is partly anti-symmetric\n",
    "    characters = []\n",
    "    from lattice_and_ops import permutation_sign\n",
    "    for perm in g.automorphisms():\n",
    "        # print(perm, \"with sign\", permutation_sign(np.asarray(perm)))\n",
    "        characters.append(permutation_sign(np.asarray(perm)))\n",
    "    characters_dimer = np.asarray(characters,dtype=complex)\n",
    "    characters_dimer_msr = characters_dimer\n",
    "else:\n",
    "    # AF phase if fully symmetric\n",
    "    characters_dimer = np.ones((len(g.automorphisms()),), dtype=complex)\n",
    "    characters_dimer_msr = characters_dimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translations\n",
    "\n",
    "If we want to include only translations, we have to exclude some symmetries from `g.automorphisms()`.\n",
    "\n",
    "\n",
    "⚠️ TODO ⚠️ <span style=\"color:red\"> This part is not fully automated yet. Translations are currently picked by hand from the group of all automorphisms. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 64 permutations, 4 translations were picked.\n"
     ]
    }
   ],
   "source": [
    "if MACHINE == \"RBMSymm_transl\" and N != 4:\n",
    "    raise NotImplementedError(\"Extraction of translations from the group of automorphisms is not implemented yet.\")\n",
    "translations = []\n",
    "for perm in g.automorphisms():\n",
    "    aperm = np.asarray(perm)\n",
    "    if (aperm[0],aperm[1]) in ((0,1),(1,0),(2,3),(3,2)): # N = 4\n",
    "    # if (aperm[0],aperm[1],aperm[3]) in ((0,1,3),(2,3,1),(8,9,11),(10,11,9)): # N = 16\n",
    "    # if (aperm[0],aperm[1],aperm[2],aperm[3]) in ((4,7,6,5),): # N = 8\n",
    "    # if (aperm[2],aperm[0]) in ((2,0),(3,0),(0,1),(1,2)):#,(2,3,1)): # N = 16, two dimers with just translation\n",
    "    # if (aperm[0],aperm[1],aperm[3]) in ((0,1,3),(3,2,0),(2,3,1),(1,0,2)): # N = 16, two dimers plus second translation option\n",
    "        translations.append(nk.utils.group._permutation_group.Permutation(aperm))\n",
    "translation_group = nk.utils.group._permutation_group.PermutationGroup(translations,degree=SITES)\n",
    "print(\"Out of\", len(g.automorphisms()), \"permutations,\",len(translation_group), \"translations were picked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1xPermutation([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])',\n",
       "  '4xPermutation([0, 1, 13, 12, 4, 5, 9, 8, 7, 6, 10, 11, 3, 2, 14, 15])',\n",
       "  '4xPermutation([0, 4, 8, 12, 1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11, 15])',\n",
       "  '8xPermutation([1, 2, 3, 0, 13, 14, 15, 12, 9, 10, 11, 8, 5, 6, 7, 4])',\n",
       "  '8xPermutation([1, 2, 6, 5, 13, 14, 10, 9, 12, 15, 11, 8, 0, 3, 7, 4])',\n",
       "  '4xPermutation([2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13])',\n",
       "  '8xPermutation([2, 3, 15, 14, 6, 7, 11, 10, 5, 4, 8, 9, 1, 0, 12, 13])',\n",
       "  '4xPermutation([2, 6, 10, 14, 3, 7, 11, 15, 0, 4, 8, 12, 1, 5, 9, 13])',\n",
       "  '8xPermutation([3, 0, 1, 2, 15, 12, 13, 14, 11, 8, 9, 10, 7, 4, 5, 6])',\n",
       "  '8xPermutation([3, 0, 4, 7, 15, 12, 8, 11, 14, 13, 9, 10, 2, 1, 5, 6])',\n",
       "  '2xPermutation([5, 4, 7, 6, 1, 0, 3, 2, 13, 12, 15, 14, 9, 8, 11, 10])',\n",
       "  '4xPermutation([5, 4, 8, 9, 1, 0, 12, 13, 2, 3, 15, 14, 6, 7, 11, 10])',\n",
       "  '1xPermutation([10, 11, 8, 9, 14, 15, 12, 13, 2, 3, 0, 1, 6, 7, 4, 5])'],\n",
       " array([[ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "          1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j,  1.+0.j,  1.+0.j,  0.+1.j,  0.+1.j, -1.+0.j, -1.+0.j,\n",
       "         -1.+0.j,  0.-1.j,  0.-1.j,  1.+0.j,  1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j,  1.+0.j,  1.+0.j,  0.-1.j,  0.-1.j, -1.+0.j, -1.+0.j,\n",
       "         -1.+0.j,  0.+1.j,  0.+1.j,  1.+0.j,  1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,\n",
       "          1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,\n",
       "          1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j, -1.+0.j,  1.+0.j,  0.+1.j,  0.-1.j, -1.+0.j,  1.+0.j,\n",
       "         -1.+0.j,  0.-1.j,  0.+1.j,  1.+0.j, -1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j, -1.+0.j,  1.+0.j,  0.-1.j,  0.+1.j, -1.+0.j,  1.+0.j,\n",
       "         -1.+0.j,  0.+1.j,  0.-1.j,  1.+0.j, -1.+0.j,  1.+0.j],\n",
       "        [ 1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,\n",
       "          1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j],\n",
       "        [ 2.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,  0.+0.j,\n",
       "         -2.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,  0.+0.j,  2.+0.j],\n",
       "        [ 2.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,\n",
       "          2.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,  0.+0.j,  2.+0.j],\n",
       "        [ 4.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j, -4.+0.j],\n",
       "        [ 4.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "          0.+0.j,  0.+0.j,  0.+0.j, -4.+0.j,  0.+0.j,  4.+0.j],\n",
       "        [ 4.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j, -4.+0.j]]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.automorphisms().character_table_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  0.+1.j,  0.+1.j,  0.+1.j,\n",
       "         0.+1.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,  0.-1.j,  0.-1.j,\n",
       "         0.-1.j,  0.-1.j,  0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j,\n",
       "        -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "        -1.+0.j,  0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j,  0.-1.j,\n",
       "         0.-1.j,  0.-1.j,  0.-1.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  0.-1.j,  0.-1.j,  0.-1.j,\n",
       "         0.-1.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,  0.+1.j,  0.+1.j,\n",
       "         0.+1.j,  0.+1.j,  0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j,\n",
       "        -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "        -1.+0.j,  0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j,  0.+1.j,\n",
       "         0.+1.j,  0.+1.j,  0.+1.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "        -1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "        -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,\n",
       "        -1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "        -1.+0.j, -1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,\n",
       "        -1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,\n",
       "         1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,\n",
       "         1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,\n",
       "        -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,\n",
       "        -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,\n",
       "         1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,\n",
       "        -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  0.+1.j,  0.-1.j,  0.+1.j,\n",
       "         0.-1.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,  0.-1.j,  0.+1.j,\n",
       "         0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j, -1.+0.j,\n",
       "         1.+0.j,  1.+0.j, -1.+0.j,  0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j,\n",
       "         1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j,  0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j, -1.+0.j,  1.+0.j,\n",
       "         1.+0.j, -1.+0.j,  0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j,\n",
       "         0.-1.j,  0.+1.j,  0.-1.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,\n",
       "         0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  0.-1.j,  0.+1.j,  0.-1.j,\n",
       "         0.+1.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,  0.+1.j,  0.-1.j,\n",
       "         0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j, -1.+0.j,\n",
       "         1.+0.j,  1.+0.j, -1.+0.j,  0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j,\n",
       "         1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j,  0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j, -1.+0.j,  1.+0.j,\n",
       "         1.+0.j, -1.+0.j,  0.-1.j,  0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j,\n",
       "         0.+1.j,  0.-1.j,  0.+1.j, -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,\n",
       "         0.+1.j,  0.-1.j,  0.+1.j,  0.-1.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,\n",
       "         1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,\n",
       "        -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,\n",
       "        -1.+0.j,  1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,\n",
       "        -1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,\n",
       "         1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j,  1.+0.j,\n",
       "        -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,  1.+0.j,\n",
       "         1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j,  1.+0.j, -1.+0.j, -1.+0.j,\n",
       "         1.+0.j],\n",
       "       [ 2.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  2.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "        -2.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j, -2.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  2.+0.j, -2.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,\n",
       "        -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,\n",
       "         2.+0.j],\n",
       "       [ 2.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "        -2.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  2.+0.j, -2.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  2.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,\n",
       "        -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,\n",
       "         2.+0.j],\n",
       "       [ 4.+0.j,  2.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j,\n",
       "         0.+0.j,  0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j, -4.+0.j,\n",
       "         0.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,  2.+0.j,\n",
       "         0.+0.j],\n",
       "       [ 4.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j, -4.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  4.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "        -4.+0.j],\n",
       "       [ 4.+0.j, -2.+0.j, -2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j, -2.+0.j,\n",
       "         0.+0.j,  0.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j, -4.+0.j,\n",
       "         0.+0.j,  2.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
       "         0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  2.+0.j, -2.+0.j,\n",
       "         0.+0.j]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.automorphisms().character_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamoltonian definition\n",
    "$$ H = J_{1} \\sum\\limits_{\\langle i,j \\rangle}^{L} \\vec{\\sigma}_{i} \\cdot \\vec{\\sigma}_{j} + J_{2} \\sum\\limits_{\\langle\\langle i,j \\rangle\\rangle_{SS}}^{L}  \\vec{\\sigma}_{i} \\cdot \\vec{\\sigma}_{j}\\,. $$\n",
    "\n",
    "Axiliary constant operators used to define hamiltonian are loaded from the external file, they are pre-defined in the `HamOps` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice_and_ops import HamOps\n",
    "ho = HamOps()\n",
    "ha_1 = nk.operator.GraphOperator(hilbert, graph=g, bond_ops=ho.bond_operator(JEXCH1,JEXCH2, use_MSR=False), bond_ops_colors=ho.bond_color)\n",
    "ha_2 = nk.operator.GraphOperator(hilbert, graph=g, bond_ops=ho.bond_operator(JEXCH1,JEXCH2, use_MSR=False), bond_ops_colors=ho.bond_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact diagonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if g.n_nodes < 20:\n",
    "    start = time.time()\n",
    "    if g.n_nodes < 15:\n",
    "        evals, eigvects = nk.exact.full_ed(ha_1, compute_eigenvectors=True)\n",
    "    else:\n",
    "        evals, eigvects = nk.exact.lanczos_ed(ha_1, k=3, compute_eigenvectors=True)\n",
    "    end = time.time()\n",
    "    diag_time = end - start\n",
    "    print(\"Ground state energy:\",evals[0], \"\\nIt took \", round(diag_time,2), \"s =\", round((diag_time)/60,2),\"min\")\n",
    "else:\n",
    "    print(\"System is too large for exact diagonalization. Setting exact_ground_energy = 0 (which is wrong)\")\n",
    "    evals = [0,0,0]\n",
    "    eigvects = None \n",
    "exact_ground_energy = evals[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine definition and other auxiliary `netket` objects\n",
    "We define two sets of these objects, usually: \n",
    "- variables ending with ...`_1` belongs to the choice of standard basis,\n",
    "- variables ending with ...`_2` belongs to the choice of MSR basis.\n",
    "\n",
    "But they can be used in a different way when we need to compare two different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of machine type\n",
    "if MACHINE == \"RBM\":\n",
    "    machine_1 = nk.models.RBM(dtype=DTYPE, alpha=ALPHA)#, use_visible_bias=False) \n",
    "    machine_2 = nk.models.RBM(dtype=DTYPE, alpha=ALPHA)#, use_visible_bias=False)\n",
    "elif MACHINE == \"RBMSymm\":\n",
    "    machine_1 = nk.models.RBMSymm(g.automorphisms(), dtype=DTYPE, alpha=ALPHA)#, use_visible_bias=False) \n",
    "    machine_2 = nk.models.RBMSymm(g.automorphisms(), dtype=DTYPE, alpha=ALPHA)#, use_visible_bias=False)\n",
    "elif MACHINE == \"RBMSymm_transl\":\n",
    "    machine_1 = nk.models.RBMSymm(translation_group, dtype=DTYPE, alpha=ALPHA)#, use_visible_bias=False) \n",
    "    machine_2 = nk.models.RBMSymm(translation_group, dtype=DTYPE, alpha=ALPHA)#, use_visible_bias=False)\n",
    "elif MACHINE == \"GCNN\":\n",
    "    machine_1 = nk.models.GCNN(symmetries=g.automorphisms(), dtype=DTYPE, \n",
    "        layers=N_LAYERS, features=FEATURES, characters=characters_dimer    )#, output_activation=log_cosh)\n",
    "    machine_2 = nk.models.GCNN(symmetries=g.automorphisms(), dtype=DTYPE, \n",
    "        layers=N_LAYERS, features=FEATURES, characters=characters_dimer_msr)#, output_activation=log_cosh)\n",
    "elif MACHINE == \"myRBM\":\n",
    "    no_of_filters = int(ALPHA/len(characters_dimer))\n",
    "    if ALPHA%len(characters_dimer) != 0:\n",
    "        raise Exception(\"Invalid ALPHA. It needs to be divisible by the number of symmetries!\")\n",
    "    from netket.nn import log_cosh\n",
    "    def identity(x):\n",
    "        return x\n",
    "    from GCNN_Nomura import GCNN_my\n",
    "    machine_1 = GCNN_my(symmetries=g.automorphisms(), dtype=DTYPE, layers=1, features=no_of_filters, \n",
    "        characters=characters_dimer, output_activation=log_cosh, use_bias=True, use_visible_bias=True)\n",
    "    machine_2 = GCNN_my(symmetries=g.automorphisms(), dtype=DTYPE, layers=1, features=no_of_filters, \n",
    "        characters=characters_dimer, output_activation=log_cosh, use_bias=True, use_visible_bias=True)\n",
    "elif MACHINE == \"Jastrow\":\n",
    "    from lattice_and_ops import Jastrow\n",
    "    machine_1 = Jastrow()\n",
    "    machine_2 = Jastrow()\n",
    "elif MACHINE == \"RBMModPhase\":\n",
    "    machine_1 = nk.models.RBMModPhase(alpha=ALPHA, use_hidden_bias=True, dtype=DTYPE)\n",
    "    machine_2 = nk.models.RBMModPhase(alpha=ALPHA, use_hidden_bias=True, dtype=DTYPE)\n",
    "\n",
    "    # A linear schedule varies the learning rate from 0 to 0.01 across 600 steps.\n",
    "    modulus_schedule_1=optax.linear_schedule(0,0.01,NUM_ITER)\n",
    "    modulus_schedule_2=optax.linear_schedule(0,0.01,NUM_ITER)\n",
    "    # The phase starts with a larger learning rate and then is decreased.\n",
    "    phase_schedule_1=optax.linear_schedule(0.05,0.01,NUM_ITER)\n",
    "    phase_schedule_2=optax.linear_schedule(0.05,0.01,NUM_ITER)\n",
    "    # Combine the linear schedule with SGD\n",
    "    optm_1=optax.sgd(modulus_schedule_1)\n",
    "    optp_1=optax.sgd(phase_schedule_1)\n",
    "    optm_2=optax.sgd(modulus_schedule_2)\n",
    "    optp_2=optax.sgd(phase_schedule_2)\n",
    "    # The multi-transform optimizer uses different optimisers for different parts of the parameters.\n",
    "    optimizer_1 = optax.multi_transform({'o1': optm_1, 'o2': optp_1}, flax.core.freeze({\"Dense_0\":\"o1\", \"Dense_1\":\"o2\"}))\n",
    "    optimizer_2 = optax.multi_transform({'o1': optm_2, 'o2': optp_2}, flax.core.freeze({\"Dense_0\":\"o1\", \"Dense_1\":\"o2\"}))\n",
    "else:\n",
    "    raise Exception(str(\"undefined MACHINE: \")+str(MACHINE))\n",
    "\n",
    "# Selection of sampler type\n",
    "if SAMPLER == 'local':\n",
    "    sampler_1 = nk.sampler.MetropolisLocal(hilbert=hilbert)\n",
    "    sampler_2 = nk.sampler.MetropolisLocal(hilbert=hilbert)\n",
    "elif SAMPLER == 'exact':\n",
    "    sampler_1 = nk.sampler.ExactSampler(hilbert=hilbert)\n",
    "    sampler_2 = nk.sampler.ExactSampler(hilbert=hilbert)\n",
    "else:\n",
    "    sampler_1 = nk.sampler.MetropolisExchange(hilbert=hilbert, graph=g)\n",
    "    sampler_2 = nk.sampler.MetropolisExchange(hilbert=hilbert, graph=g)\n",
    "    if SAMPLER != 'exchange':\n",
    "        print(\"Warning! Undefined fq.SAMPLER:\", SAMPLER, \", dafaulting to MetropolisExchange fq.SAMPLER\")\n",
    "\n",
    "optimizer_1 = nk.optimizer.Sgd(learning_rate=ETA)\n",
    "optimizer_2 = nk.optimizer.AdaGrad(learning_rate=ETA)\n",
    "\n",
    "# Stochastic Reconfiguration as a preconditioner\n",
    "sr_1  = nk.optimizer.SR(diag_shift=0.01)\n",
    "sr_2  = nk.optimizer.SR(diag_shift=0.01)\n",
    "\n",
    "# The variational state (former name: nk.variational.MCState)\n",
    "vs_1 = nk.vqs.MCState(sampler_1 , machine_1 , n_samples=SAMPLES)\n",
    "vs_2 = nk.vqs.MCState(sampler_2 , machine_2 , n_samples=SAMPLES)\n",
    "vs_1.init_parameters(jax.nn.initializers.normal(stddev=0.001))\n",
    "vs_2.init_parameters(jax.nn.initializers.normal(stddev=0.001))\n",
    "\n",
    "\n",
    "gs_1 = nk.VMC(hamiltonian=ha_1 ,optimizer=optimizer_1 ,preconditioner=sr_1 ,variational_state=vs_1)\n",
    "gs_2 = nk.VMC(hamiltonian=ha_2 ,optimizer=optimizer_2 ,preconditioner=sr_2 ,variational_state=vs_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2192 2192\n"
     ]
    }
   ],
   "source": [
    "print(vs_1.n_parameters, vs_2.n_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation\n",
    "We let the calculation run for `NUM_ITERS` iterations for both cases _1 and _2 (without MSR and with MSR). If only one case is desired, set the variable `no_of_runs` to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_1 = 0.9; Expected exact energy: -34.081907786031174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:35<00:00,  1.93it/s, Energy=-22.08-0.15j ± 0.21 [σ²=60.17]]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation for RBM of type 1 took 2.598356227080027 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "runs = [1,1]\n",
    "no_of_runs = np.sum(runs) # 1 - one run for variables with ..._1;  2 - both runs for variables ..._1 and ..._2\n",
    "run_only_2 = (runs[1]==1 and runs[0]==0) # in case of no_of_runs=1\n",
    "NUM_ITER = 300#3000\n",
    "print(\"J_1 =\", JEXCH1, end=\"; \")\n",
    "if exact_ground_energy != 0:\n",
    "    print(\"Expected exact energy:\", exact_ground_energy)\n",
    "for i,gs in enumerate([gs_1,gs_2][run_only_2:run_only_2+no_of_runs]):\n",
    "    start = time.time()\n",
    "    gs.run(out=OUT_NAME+str(i), n_iter=int(NUM_ITER))#, obs={'symmetry':P(0,1)})\n",
    "    end = time.time()\n",
    "    print(\"The calculation for {} of type {} took {} min\".format(MACHINE, i+1, (end-start)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Convergence Plotting\n",
    "In case that the machine did not converge, we can re-run the previous cell and than skip the next cell. This way, the replotting just appends the new results and does not erase the previoius results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact Energy Line\n",
    "no_of_all_iters = NUM_ITER\n",
    "figure = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=(0,no_of_all_iters),\n",
    "            y=(exact_ground_energy,exact_ground_energy),\n",
    "            mode=\"lines\",line=go.scatter.Line(color=\"#000000\",width=1), name=\"exact energy\")],\n",
    "    layout=go.Layout(\n",
    "        template=\"simple_white\",\n",
    "        xaxis=dict(title=\"Iteration\", mirror=True, showline=True),\n",
    "        yaxis=dict(title=\"Energy\", mirror=True, showline=True),\n",
    "        title=(\"<b>\"+\"S-S\"+\" model </b>, L=\"+str(SITES)+\", J2 =\"+str(JEXCH2)+ \", J1 =\"+str(JEXCH1)+\" , η=\"+str(ETA)+\", α=\"+str(ALPHA)+\", samples=\"+str(SAMPLES)))\n",
    "    ).add_hline(y=exact_ground_energy, opacity=1, line_width=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SS_16j1=0.90.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7937/733520037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_of_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_NAME_suffixless\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AdaGrad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Energy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#DTYPE in (np.complex128, np.complex64):#, np.float64):# and False:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SS_16j1=0.90.log'"
     ]
    }
   ],
   "source": [
    "# import the data from log file\n",
    "OUT_NAME_suffixless=OUT_NAME\n",
    "data = []\n",
    "for i in range(no_of_runs):\n",
    "    data.append(json.load(open(OUT_NAME_suffixless+str(i)+\".log\")))\n",
    "names = [\"SGD\",\"AdaGrad\"]\n",
    "if type(data[0][\"Energy\"][\"Mean\"]) == dict: #DTYPE in (np.complex128, np.complex64):#, np.float64):# and False:\n",
    "    energy_convergence = [data[i][\"Energy\"][\"Mean\"][\"real\"] for i in range(no_of_runs)]\n",
    "    # symmetry = [data[i][\"symmetry\"][\"Mean\"][\"real\"] for i in range(no_of_runs-run_only_2)]\n",
    "else:\n",
    "    energy_convergence = [data[i][\"Energy\"][\"Mean\"] for i in range(no_of_runs)]\n",
    "    # symmetry = [data[i][\"symmetry\"][\"Mean\"] for i in range(no_of_runs-run_only_2)]\n",
    "for i in range(no_of_runs):\n",
    "    figure.add_trace(go.Scatter(\n",
    "        x=data[i][\"Energy\"][\"iters\"], y=energy_convergence[i],\n",
    "        name=names[i]\n",
    "    ))\n",
    "    # figure.add_trace(go.Scatter(\n",
    "    #     x=data[i][\"Energy\"][\"iters\"], y=symmetry[i],\n",
    "    #     name=names[i]+\"_swap\"\n",
    "    # ))\n",
    "\n",
    "figure.update_layout(xaxis_title=\"Iteration\",yaxis_title=\"Energy\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of the other simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 8]\n"
     ]
    }
   ],
   "source": [
    "# Calculation of how long it took to reach 99.5% of exact energy. The first value under 0.5% deviation counts as a converged state.\n",
    "no_of_runs = 2\n",
    "threshold_energy = 0.995*exact_ground_energy\n",
    "data = []\n",
    "for i in range(no_of_runs):\n",
    "    data.append(json.load(open(OUT_NAME+str(i)+\".log\")))\n",
    "if type(data[0][\"Energy\"][\"Mean\"]) == dict:\n",
    "    energy_convergence = [data[i][\"Energy\"][\"Mean\"][\"real\"] for i in range(no_of_runs)]\n",
    "else:\n",
    "    energy_convergence = [data[i][\"Energy\"][\"Mean\"] for i in range(no_of_runs)]\n",
    "steps_until_convergence = [next((i for i,v in enumerate(energy_convergence[j]) if v < threshold_energy), -1) for j in range(no_of_runs)]\n",
    "print(steps_until_convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained RBM without MSR:\n",
      "m_d^2 = -0.2522-0.0015j ± 0.0040 [σ²=0.0117]\n",
      "m_p(MSR) = -0.056+0.009j ± 0.029 [σ²=0.796]\n",
      "m_s^2 = 0.3366-0.0004j ± 0.0086 [σ²=0.1060]\n",
      "m_s^2(MSR) = 1.016+0.005j ± 0.011 [σ²=0.087]\n",
      "Trained RBM with MSR:\n",
      "m_d^2 = -0.333334+0.000006j ± 0.000014 [σ²=0.000000]\n",
      "m_p(MSR) = 0.022-0.000j ± 0.051 [σ²=2.004]\n",
      "m_s^2 = 1.1245-0.0000j ± 0.0040 [σ²=0.0148]\n",
      "m_s^2(MSR) = 0.1250007-0.0000012j ± 0.0000080 [σ²=0.0000001]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of order parameters.\n",
    "from lattice_and_ops import Operators, Lattice\n",
    "ops = Operators(lattice,hilbert,ho.mszsz,ho.exchange)\n",
    "for i,gs in enumerate([gs_1,gs_2][run_only_2:run_only_2+no_of_runs]):\n",
    "    print(\"Trained RBM with MSR:\" if i else \"Trained RBM without MSR:\")\n",
    "    print(\"m_d^2 =\", gs.estimate(ops.m_dimer_op))\n",
    "    print(\"m_p(MSR) =\", gs.estimate(ops.m_plaquette_op_MSR))\n",
    "    print(\"m_s^2 =\", gs.estimate(ops.m_s2_op_MSR))\n",
    "    print(\"m_s^2(MSR) =\", gs.estimate(ops.m_s2_op))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.90000     -33.66302     -0.25219     -0.07190      1.01584    1000.00000    300.00000     -1.00000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:9.5f}     {:9.5f}    {:9.5f}    {:9.5f}    {:9.5f}    {:9.5f}    {:9.5f}    {:9.5f}\".format(JEXCH1, gs_1.energy.mean.real, gs_1.estimate(ops.m_dimer_op).mean.real, gs_1.estimate(ops.m_plaquette_op).mean.real, gs_1.estimate(ops.m_s2_op).mean.real, SAMPLES, NUM_ITER, steps_until_convergence[0], sep='    '))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
